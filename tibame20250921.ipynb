{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0iq3O4+EBkKHhP55ytWdV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibame_night_20250825/blob/main/tibame20250921.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9wnZaRD1Lnt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "\n",
        "def download_meta(url):\n",
        "    # url = \"https://www.ptt.cc/bbs/Beauty/M.1758273800.A.03F.html\"\n",
        "    resp = req.urlopen(url)\n",
        "    content = resp.read()\n",
        "    html = bs.BeautifulSoup(content)\n",
        "\n",
        "    metas = html.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
        "    uid = metas[0]\n",
        "    board = metas[1]\n",
        "    title = metas[2]\n",
        "    posttime = metas[3]\n",
        "\n",
        "\n",
        "    uid_text = uid.get_text().strip()\n",
        "    board_text = board.get_text().strip()\n",
        "    title_text = title.get_text().strip()\n",
        "    posttime_text = posttime.get_text().strip()\n",
        "\n",
        "    pushes = html.find_all(\"div\", {\"class\":\"push\"})\n",
        "    push_list = []\n",
        "    for p in pushes:\n",
        "        trans = {\"推\":1, \"→\":0, \"噓\":-1}\n",
        "        pushtag = p.find(\"span\", {\"class\":\"push-tag\"})\n",
        "        pushuid = p.find(\"span\", {\"class\":\"push-userid\"})\n",
        "        pushcontent = p.find(\"span\", {\"class\":\"push-content\"})\n",
        "        pushipdatetime = p.find(\"span\", {\"class\":\"push-ipdatetime\"})\n",
        "\n",
        "        pushtag_text = pushtag.get_text().strip()\n",
        "        pushtag_score = trans[pushtag_text]\n",
        "        pushuid_text = pushuid.get_text().strip()\n",
        "        pushcontent_text = pushcontent.get_text().strip().replace(\": \", \"\")\n",
        "        pushipdatetime_text = pushipdatetime.get_text().strip()\n",
        "\n",
        "        push_meta = {\n",
        "            \"score\": pushtag_score,\n",
        "            \"uid\": pushuid_text,\n",
        "            \"content\": pushcontent_text,\n",
        "            \"ipdatetime\": pushipdatetime_text\n",
        "        }\n",
        "        push_list.append(push_meta)\n",
        "\n",
        "    # extract: 我都放最後做(因為刪了就刪了)\n",
        "    maincontent = html.find(\"div\", {\"id\":\"main-content\"})\n",
        "    targets = html.find_all(\"div\", {\"class\":\"article-metaline\"})\n",
        "    for t in targets:\n",
        "        t.extract()\n",
        "    targets = html.find_all(\"div\", {\"class\":\"article-metaline-right\"})\n",
        "    for t in targets:\n",
        "        t.extract()\n",
        "    targets = html.find_all(\"div\", {\"class\":\"push\"})\n",
        "    for t in targets:\n",
        "        t.extract()\n",
        "    maincontent_text = maincontent.get_text()\n",
        "\n",
        "    # userid/看板名稱/標題/時間  推虛文: 推需>/userid/內容/ipdatetime\n",
        "    row = {\n",
        "        \"uid\": uid_text,\n",
        "        \"board\": board_text,\n",
        "        \"title\": title_text,\n",
        "        \"time\": posttime_text,\n",
        "        \"content\": maincontent_text,\n",
        "        \"pushes\": push_list\n",
        "    }\n",
        "\n",
        "    dn = url.split(\"/\")[-1]\n",
        "    fn = dn + \"/\" + \"metadata.json\"\n",
        "    print(\"Save to:\", fn)\n",
        "    # 如果資料夾不存在, 就make起來\n",
        "    if not os.path.exists(dn):\n",
        "        os.makedirs(dn)\n",
        "\n",
        "    with open(fn, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(row, f, ensure_ascii=False, indent=4)"
      ]
    }
  ]
}